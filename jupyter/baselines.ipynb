{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from Levenshtein import distance\n",
    "from utils import rm_idx, match_idx\n",
    "from metrics import Metrics\n",
    "\n",
    "\n",
    "def load_pickle(filename):\n",
    "    if filename is None or not os.path.exists(filename):\n",
    "        return None\n",
    "    with open(filename, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def save_pickle(data, filename):\n",
    "    if filename is None:\n",
    "        return\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluating SFTTestSeqRec Top10 gpt-3.5-turbo-1106_output\n",
    "res_file = [\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRec_LCT_Top10.pickle_Result0-999.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRec_LCT_Top10.pickle_Result1000-1499.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRec_LCT_Top10.pickle_Result1500-1999.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRec_LCT_Top10.pickle_Result2000-3999.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRec_LCT_Top10.pickle_Result4000-4999.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRec_LCT_Top10.pickle_gpt-3.5-turbo-1106_Result5000-7199.jsonl',\n",
    "]\n",
    "meta = load_pickle('../data/dataset/steam/meta1.pickle')\n",
    "title = [meta[_]['title'] for _ in meta]\n",
    "title = [re.sub(r' +', ' ', _) for _ in title]\n",
    "title = [re.sub(r': +', ':', _) for _ in title]\n",
    "title = [re.sub(r', +', ',', _) for _ in title]\n",
    "gpt_seq_rec_data_top10 = []\n",
    "for _ in res_file:\n",
    "    old_len = len(gpt_seq_rec_data_top10)\n",
    "    for idx, __ in enumerate(open(_, mode='r', encoding=\"utf-8\").readlines()):\n",
    "        try:\n",
    "            gpt_seq_rec_data_top10.append(json.loads(__))\n",
    "        except Exception as e:\n",
    "            print('error: ', e, '\\nidx: ', idx, 'of', _)\n",
    "    print(_, f' | count: {len(gpt_seq_rec_data_top10)-old_len}')\n",
    "\n",
    "k = 10\n",
    "recall, mrr, ndcg, repeat, not_exist, in_history, correct_count = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "count = len(gpt_seq_rec_data_top10)\n",
    "for _ in tqdm(gpt_seq_rec_data_top10):\n",
    "    if _['gpt-3.5-turbo-1106_output'][0] == _['gpt-3.5-turbo-1106_output'][-1] == '\"' or _['gpt-3.5-turbo-1106_output'][0] == _['gpt-3.5-turbo-1106_output'][-1] == \"'\":\n",
    "        _['gpt-3.5-turbo-1106_output'] = _['gpt-3.5-turbo-1106_output'][1:-1]\n",
    "    history = re.sub(r' +', ' ', _['input_field_data']['history'])\n",
    "    history = re.sub(r': +', ':', history)\n",
    "    history = re.sub(r', +', ',', history)\n",
    "    if ' 鈫?' in history:\n",
    "        history = [__[1:-1] for __ in history.split(' 鈫?')]\n",
    "    else:\n",
    "        history = [__[1:-1] for __ in history.split(' → ')]\n",
    "    assert len(history) > 1\n",
    "\n",
    "    label = rm_idx(_['output_text'])\n",
    "    label = re.sub(r' +', ' ', label)\n",
    "    label = re.sub(r': +', ':', label)\n",
    "    label = re.sub(r', +', ',', label)\n",
    "\n",
    "    ts = _['gpt-3.5-turbo-1106_output'].split('\\n')\n",
    "    if len(ts) == 1:\n",
    "        ts = _['gpt-3.5-turbo-1106_output'].split(\"', '\")\n",
    "    ts = [rm_idx(__).strip().split('\\n')[0].strip() for __ in ts]\n",
    "    ts = [__[2:] if __.startswith('- ') else __ for __ in ts]\n",
    "    ts = [re.sub(r' +', ' ', __) for __ in ts]\n",
    "    ts = [re.sub(r': +', ':', __) for __ in ts]\n",
    "    ts = [re.sub(r', +', ',', __) for __ in ts]\n",
    "    ts = [__[1:-1] if __[0] == __[-1] == \"'\" or __[0] == __[-1] == \"\\\"\" else __ for __ in ts if __ != '']\n",
    "    ts = [__.strip() for __ in ts]\n",
    "    ts = ts[:k]\n",
    "    # for idx, __ in enumerate(ts):\n",
    "    #     if __ in title:\n",
    "    #         continue\n",
    "    #     for ___ in title:\n",
    "    #         if distance(__, ___) <= 3:\n",
    "    #             ts[idx] = ___\n",
    "    #             break\n",
    "    recall += 1 if label in ts else 0\n",
    "    mrr += 1/(ts.index(label)+1) if label in ts else 0\n",
    "    ndcg += 1/math.log2(ts.index(label)+2) if label in ts else 0\n",
    "    repeat += sum([1 for idx, __ in enumerate(ts) if __ in ts[:idx]])\n",
    "    not_exist += sum([1 for __ in ts if __ not in title])\n",
    "    in_history += sum([1 for __ in ts if __ in history])\n",
    "    # if sum([1 for __ in ts if __ not in title]) > 0:\n",
    "    #     print(_['gpt-3.5-turbo-1106_output'])\n",
    "    #     print([__ for __ in ts if __ not in title])\n",
    "    #     print('')\n",
    "    correct_count += 1 if len(ts) == _['input_field_data']['item_count'] else 0\n",
    "print(f'''top_k: {k}\n",
    "count: {len(gpt_seq_rec_data_top10)}\n",
    "recall: {recall/len(gpt_seq_rec_data_top10):.5f}\n",
    "mrr: {mrr/len(gpt_seq_rec_data_top10):.5f}\n",
    "ndcg: {ndcg/len(gpt_seq_rec_data_top10):.5f}\n",
    "repeat: {repeat/len(gpt_seq_rec_data_top10):.5f}\n",
    "not_exist: {not_exist/len(gpt_seq_rec_data_top10):.5f}\n",
    "in_history: {in_history/len(gpt_seq_rec_data_top10):.5f}\n",
    "correct_count: {correct_count/len(gpt_seq_rec_data_top10):.5f}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluating SFTTestSeqRanking Top5 gpt-3.5-turbo-1106_output\n",
    "res_file = [\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRanking_LCT_Top5.pickle_Result0-9.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRanking_LCT_Top5.pickle_Result10-2999.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRanking_LCT_Top5.pickle_Result3000-4999.jsonl',\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRanking_LCT_Top5.pickle_gpt-3.5-turbo-1106_Result5000-6599.jsonl',\n",
    "]\n",
    "gpt_seq_ranking_data_top5 = []\n",
    "for _ in res_file:\n",
    "    old_len = len(gpt_seq_ranking_data_top5)\n",
    "    for idx, __ in enumerate(open(_, mode='r', encoding=\"utf-8\").readlines()):\n",
    "        try:\n",
    "            gpt_seq_ranking_data_top5.append(json.loads(__))\n",
    "        except Exception as e:\n",
    "            print('error: ', e, '\\nidx: ', idx, 'of', _)\n",
    "    print(_, f' | count: {len(gpt_seq_ranking_data_top5)-old_len}')\n",
    "\n",
    "k = 5\n",
    "recall, mrr, ndcg, repeat, correct_count, out_of_candidate = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "count = len(gpt_seq_ranking_data_top5)\n",
    "for _ in tqdm(gpt_seq_ranking_data_top5):\n",
    "    if _['gpt-3.5-turbo-1106_output'][0] == _['gpt-3.5-turbo-1106_output'][-1] == '\"' or _['gpt-3.5-turbo-1106_output'][0] == _['gpt-3.5-turbo-1106_output'][-1] == \"'\":\n",
    "        _['gpt-3.5-turbo-1106_output'] = _['gpt-3.5-turbo-1106_output'][1:-1]\n",
    "    candidates = re.sub(r' +', ' ', _['input_field_data']['candidate_titles'])\n",
    "    candidates = re.sub(r': +', ':', candidates)\n",
    "    candidates = re.sub(r', +', ',', candidates)\n",
    "    candidates = [__[1:-1] for __ in candidates.split(',')]\n",
    "\n",
    "    label = rm_idx(_['output_text'])\n",
    "    label = re.sub(r' +', ' ', label)\n",
    "    label = re.sub(r': +', ':', label)\n",
    "    label = re.sub(r', +', ',', label)\n",
    "\n",
    "    ts = _['gpt-3.5-turbo-1106_output'].split('\\n')\n",
    "    if len(ts) == 1:\n",
    "        ts = _['gpt-3.5-turbo-1106_output'].split(\"', '\")\n",
    "    ts = [rm_idx(__).strip().split('\\n')[0].strip() for __ in ts]\n",
    "    ts = [__[2:] if __.startswith('- ') else __ for __ in ts]\n",
    "    ts = [re.sub(r' +', ' ', __) for __ in ts]\n",
    "    ts = [re.sub(r': +', ':', __) for __ in ts]\n",
    "    ts = [re.sub(r', +', ',', __) for __ in ts]\n",
    "    ts = [__[1:-1] if __[0] == __[-1] == \"'\" or __[0] == __[-1] == \"\\\"\" else __ for __ in ts if __ != '']\n",
    "    ts = [__.strip() for __ in ts]\n",
    "    ts = ts[:k]\n",
    "\n",
    "    for idx, __ in enumerate(ts):\n",
    "        if __ in candidates:\n",
    "            continue\n",
    "        for ___ in candidates:\n",
    "            if distance(__, ___) <= 3:\n",
    "                ts[idx] = ___\n",
    "    recall += 1 if label in ts else 0\n",
    "    mrr += 1/(ts.index(label)+1) if label in ts else 0\n",
    "    ndcg += 1/math.log2(ts.index(label)+2) if label in ts else 0\n",
    "    repeat += sum([1 for idx, __ in enumerate(ts) if __ in ts[:idx]])\n",
    "    out_of_candidate += sum([1 for __ in ts if __ not in candidates])\n",
    "    # if sum([1 for __ in ts if __ not in candidates]) > 0:\n",
    "    #     print(_['gpt-3.5-turbo-1106_output'])\n",
    "    #     print([__ for __ in ts if __ not in candidates], candidates)\n",
    "    #     print('')\n",
    "    correct_count += 1 if len(ts) == _['input_field_data']['item_count'] else 0\n",
    "print(f'''top_k: {k}\n",
    "count: {count}\n",
    "recall: {recall/count:.5f}\n",
    "mrr: {mrr/count:.5f}\n",
    "ndcg: {ndcg/count:.5f}\n",
    "repeat: {repeat/count:.5f}\n",
    "out_of_candidate: {out_of_candidate/count:.5f}\n",
    "correct_count: {correct_count/count:.5f}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluating SFTTestSeqRec Top10 Llama-2-7b-hf-chat_output\n",
    "res_file = [\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRec_LCT_Top10.pickle_Llama-2-7b-hf-chat_Result0-13217.jsonl',\n",
    "]\n",
    "meta = load_pickle('../data/dataset/steam/meta1.pickle')\n",
    "title = [meta[_]['title'] for _ in meta]\n",
    "title = [re.sub(r' +', ' ', _) for _ in title]\n",
    "title = [re.sub(r': +', ':', _) for _ in title]\n",
    "title = [re.sub(r', +', ',', _) for _ in title]\n",
    "gpt_seq_rec_data_top10 = []\n",
    "for _ in res_file:\n",
    "    old_len = len(gpt_seq_rec_data_top10)\n",
    "    for idx, __ in enumerate(open(_, mode='r', encoding=\"utf-8\").readlines()[:]):\n",
    "        try:\n",
    "            gpt_seq_rec_data_top10.append(json.loads(__))\n",
    "        except Exception as e:\n",
    "            print('error: ', e, '\\nidx: ', idx, 'of', _)\n",
    "    print(_, f' | count: {len(gpt_seq_rec_data_top10)-old_len}')\n",
    "\n",
    "print(gpt_seq_rec_data_top10[0])\n",
    "k = 10\n",
    "recall, mrr, ndcg, repeat, not_exist, in_history, target_in_history, correct_count = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "count = len(gpt_seq_rec_data_top10)\n",
    "for _ in tqdm(gpt_seq_rec_data_top10):\n",
    "    if _['Llama-2-7b-hf-chat_output'][0] == _['Llama-2-7b-hf-chat_output'][-1] == '\"' or _['Llama-2-7b-hf-chat_output'][0] == _['Llama-2-7b-hf-chat_output'][-1] == \"'\":\n",
    "        _['Llama-2-7b-hf-chat_output'] = _['Llama-2-7b-hf-chat_output'][1:-1]\n",
    "    history = re.sub(r' +', ' ', _['input_field_data']['history'])\n",
    "    history = re.sub(r': +', ':', history)\n",
    "    history = re.sub(r', +', ',', history)\n",
    "    if ' â\\x86\\x92 ' in history:\n",
    "        history = [__[1:-1] for __ in history.split(' â\\x86\\x92 ')]\n",
    "    else:\n",
    "        history = [__[1:-1] for __ in history.split(' → ')]\n",
    "    assert len(history) > 1\n",
    "\n",
    "    label = rm_idx(_['output_text'])\n",
    "    label = re.sub(r' +', ' ', label)\n",
    "    label = re.sub(r': +', ':', label)\n",
    "    label = re.sub(r', +', ',', label)\n",
    "\n",
    "    ts = _['Llama-2-7b-hf-chat_output'].split('\\n')\n",
    "    ts = [rm_idx(__).strip().split('\\n')[0].strip() for __ in ts if match_idx(__)]\n",
    "    ts = [re.sub(r' +', ' ', __) for __ in ts]\n",
    "    ts = [re.sub(r': +', ':', __) for __ in ts]\n",
    "    ts = [re.sub(r', +', ',', __) for __ in ts]\n",
    "    ts = [__[1:-1] if __[0] == __[-1] == \"'\" or __[0] == __[-1] == \"\\\"\" else __ for __ in ts if __ != '']\n",
    "    ts = [__.strip() for __ in ts]\n",
    "    ts = ts[:k]\n",
    "\n",
    "    for idx, __ in enumerate(ts):\n",
    "        if __ in title:\n",
    "            continue\n",
    "        for ___ in title:\n",
    "            if distance(__, ___) <= 3:\n",
    "                ts[idx] = ___\n",
    "                break\n",
    "    recall += 1 if label in ts else 0\n",
    "    mrr += 1/(ts.index(label)+1) if label in ts else 0\n",
    "    ndcg += 1/math.log2(ts.index(label)+2) if label in ts else 0\n",
    "    repeat += sum([1 for idx, __ in enumerate(ts) if __ in ts[:idx]])\n",
    "    not_exist += sum([1 for __ in ts if __ not in title])\n",
    "    in_history += sum([1 for __ in ts if __ in history])\n",
    "    target_in_history += 1 if label in history else 0\n",
    "    correct_count += 1 if len(ts) == _['input_field_data']['item_count'] else 0\n",
    "print(f'''top_k: {k}\n",
    "count: {len(gpt_seq_rec_data_top10)}\n",
    "recall: {recall/len(gpt_seq_rec_data_top10):.5f}\n",
    "mrr: {mrr/len(gpt_seq_rec_data_top10):.5f}\n",
    "ndcg: {ndcg/len(gpt_seq_rec_data_top10):.5f}\n",
    "repeat: {repeat/len(gpt_seq_rec_data_top10):.5f}\n",
    "not_exist: {not_exist/len(gpt_seq_rec_data_top10):.5f}\n",
    "in_history: {in_history/len(gpt_seq_rec_data_top10):.5f}\n",
    "target_in_history: {target_in_history/len(gpt_seq_rec_data_top10):.5f}\n",
    "correct_count: {correct_count/len(gpt_seq_rec_data_top10):.5f}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluating SFTTestSeqRec Top10 Llama-2-7b-hf-chat_output\n",
    "res_file = [\n",
    "    '../data/dataset/sub_movie/GPT_datum_info_test_SFTTestSeqRanking_LCT_Top5.pickle_Llama-2-7b-hf-chat_Result0-13217.jsonl',\n",
    "]\n",
    "gpt_seq_rec_data_top10 = []\n",
    "for _ in res_file:\n",
    "    old_len = len(gpt_seq_rec_data_top10)\n",
    "    for idx, __ in enumerate(open(_, mode='r', encoding=\"utf-8\").readlines()[:]):\n",
    "        try:\n",
    "            gpt_seq_rec_data_top10.append(json.loads(__))\n",
    "        except Exception as e:\n",
    "            print('error: ', e, '\\nidx: ', idx, 'of', _)\n",
    "    print(_, f' | count: {len(gpt_seq_rec_data_top10)-old_len}')\n",
    "\n",
    "k = 5\n",
    "recall, mrr, ndcg, repeat, correct_count, out_of_candidate = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "count = len(gpt_seq_rec_data_top10)\n",
    "for _ in tqdm(gpt_seq_rec_data_top10):\n",
    "    if _['Llama-2-7b-hf-chat_output'][0] == _['Llama-2-7b-hf-chat_output'][-1] == '\"' or _['Llama-2-7b-hf-chat_output'][0] == _['Llama-2-7b-hf-chat_output'][-1] == \"'\":\n",
    "        _['Llama-2-7b-hf-chat_output'] = _['Llama-2-7b-hf-chat_output'][1:-1]\n",
    "    candidates = re.sub(r' +', ' ', _['input_field_data']['candidate_titles'])\n",
    "    candidates = re.sub(r': +', ':', candidates)\n",
    "    candidates = re.sub(r', +', ',', candidates)\n",
    "    candidates = [__[1:-1] for __ in candidates.split(',')]\n",
    "\n",
    "    label = rm_idx(_['output_text'])\n",
    "    label = re.sub(r' +', ' ', label)\n",
    "    label = re.sub(r': +', ':', label)\n",
    "    label = re.sub(r', +', ',', label)\n",
    "\n",
    "    ts = _['Llama-2-7b-hf-chat_output'].split('\\n')\n",
    "    ts = [rm_idx(__).strip().split('\\n')[0].strip() for __ in ts if match_idx(__)]\n",
    "    ts = [re.sub(r' +', ' ', __) for __ in ts]\n",
    "    ts = [re.sub(r': +', ':', __) for __ in ts]\n",
    "    ts = [re.sub(r', +', ',', __) for __ in ts]\n",
    "    ts = [__[1:-1] if __[0] == __[-1] == \"'\" or __[0] == __[-1] == \"\\\"\" else __ for __ in ts if __ != '']\n",
    "    ts = [__.strip() for __ in ts]\n",
    "    ts = ts[:k]\n",
    "\n",
    "    for idx, __ in enumerate(ts):\n",
    "        if __ in candidates:\n",
    "            continue\n",
    "        for ___ in candidates:\n",
    "            if distance(__, ___) <= 3:\n",
    "                ts[idx] = ___\n",
    "    recall += 1 if label in ts else 0\n",
    "    mrr += 1/(ts.index(label)+1) if label in ts else 0\n",
    "    ndcg += 1/math.log2(ts.index(label)+2) if label in ts else 0\n",
    "    repeat += sum([1 for idx, __ in enumerate(ts) if __ in ts[:idx]])\n",
    "    out_of_candidate += sum([1 for __ in ts if __ not in candidates])\n",
    "    # if sum([1 for __ in ts if __ not in candidates]) > 0:\n",
    "    #     print(_['Llama-2-7b-hf-chat_output'])\n",
    "    #     print([__ for __ in ts if __ not in candidates], candidates)\n",
    "    #     print('')\n",
    "    correct_count += 1 if len(ts) == _['input_field_data']['item_count'] else 0\n",
    "print(f'''top_k: {k}\n",
    "count: {len(gpt_seq_rec_data_top10)}\n",
    "recall: {recall/len(gpt_seq_rec_data_top10):.5f}\n",
    "mrr: {mrr/len(gpt_seq_rec_data_top10):.5f}\n",
    "ndcg: {ndcg/len(gpt_seq_rec_data_top10):.5f}\n",
    "repeat: {repeat/len(gpt_seq_rec_data_top10):.5f}\n",
    "out_of_candidate: {out_of_candidate/len(gpt_seq_rec_data_top10):.5f}\n",
    "correct_count: {correct_count/len(gpt_seq_rec_data_top10):.5f}''')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# dataset, item_index = 'sub_movie', 'title64_t'\n",
    "dataset, item_index = 'steam', 'title'\n",
    "task, k = 'SFTTestSeqRec', 10\n",
    "# task, k = 'SFT+TestPersonalControlRec', 10\n",
    "# task, k = 'SFT-TestPersonalControlRec', 10\n",
    "# task, k = 'SFTTestPersonalCategoryRate_30', 10\n",
    "# task, k = 'SFTTestPersonalCategoryRate_50', 10\n",
    "# task, k = 'SFTTestPersonalCategoryRate_70', 10\n",
    "\n",
    "model = f'snap/Llama-2-7b-hf-chat/'\n",
    "category2item = load_pickle(f'../data/dataset/{dataset}/category1.pickle')\n",
    "meta = load_pickle(f'../data/dataset/{dataset}/meta1.pickle')\n",
    "res_file = [\n",
    "    f\"/home/lws/projects/InstructControllableRec_RLHF/{model}{dataset}/{task}_Top10_Result_Sample.pickle\"\n",
    "]\n",
    "\n",
    "title2item = {}\n",
    "for _ in meta:\n",
    "    if title2item.get(meta[_][item_index]) is None:\n",
    "        title2item[meta[_][item_index]] = []\n",
    "    title2item[meta[_][item_index]].append(_)\n",
    "\n",
    "def vague_mapping(d):\n",
    "    if d[f'{model}_output'] == \"\":\n",
    "        d[f'{task}_output_title_list'] = []\n",
    "        return d\n",
    "\n",
    "    if d[f'{model}_output'][0] == d[f'{model}_output'][-1] == '\"' or d[f'{model}_output'][0] == d[f'{model}_output'][-1] == \"'\":\n",
    "        d[f'{model}_output'] = d[f'{model}_output'][1:-1]\n",
    "\n",
    "    ts = d[f'{model}_output'].split('\\n')\n",
    "    ts = [rm_idx(_).strip().split('\\n')[0].strip() for _ in ts if match_idx(_)]\n",
    "    if task != 'SFTTestSeqRec':\n",
    "        ts = [re.sub(r' *[(,\\[](.*)[),\\]]$', '', _) for _ in ts]\n",
    "    ts = [_[1:-1] if _[0] == _[-1] == \"'\" or _[0] == _[-1] == \"\\\"\" else _ for _ in ts if _ != '']\n",
    "    ts = [_.strip() for _ in ts]\n",
    "    ts = ts[:k]\n",
    "    if \"SeqRec_Result\" in d[\"input_field_data\"]:\n",
    "        d['input_field_data']['SeqRec_Result'] = d['input_field_data']['SeqRec_Result'][:k]\n",
    "    d['input_field_data']['item_count'] = k\n",
    "    d[f'{task}_output_title_list'] = ts\n",
    "    for idx, _ in enumerate(d[f'{task}_output_title_list']):\n",
    "        if _ in title2item:\n",
    "            continue\n",
    "        for __ in title2item:\n",
    "            if distance(_, __) <= 3:\n",
    "                ts[idx] = __\n",
    "                break\n",
    "    return d\n",
    "\n",
    "metric = Metrics([task], k, category2item, title2item)\n",
    "\n",
    "gpt_seq_rec_data_top10 = []\n",
    "for _ in res_file:\n",
    "    old_len = len(gpt_seq_rec_data_top10)\n",
    "    gpt_seq_rec_data_top10.extend(load_pickle(_))\n",
    "    print(_, f' | count: {len(gpt_seq_rec_data_top10)-old_len}')\n",
    "recall, mrr, ndcg, repeat, not_exist, in_history, target_in_history, correct_count = 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "count = 0\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=80) as executor:\n",
    "    results = list(tqdm(executor.map(vague_mapping, gpt_seq_rec_data_top10), total=len(gpt_seq_rec_data_top10)))\n",
    "\n",
    "for _ in tqdm(results):\n",
    "    if len(_[f'{task}_output_title_list']) == 0:\n",
    "        continue\n",
    "    history = _['input_field_data']['history']\n",
    "    if ' â\\x86\\x92 ' in history:\n",
    "        history = [__[1:-1] for __ in history.split(' â\\x86\\x92 ')]\n",
    "    else:\n",
    "        history = [__[1:-1] for __ in history.split(' → ')]\n",
    "    assert len(history) > 1\n",
    "    label = rm_idx(_['output_text'])\n",
    "    ts = _[f'{task}_output_title_list']\n",
    "    metric.add_sample(task, _['input_field_data'], ts, [label], vague_mapping=False)\n",
    "    count += 1\n",
    "    recall += 1 if label in ts else 0\n",
    "    mrr += 1/(ts.index(label)+1) if label in ts else 0\n",
    "    ndcg += 1/math.log2(ts.index(label)+2) if label in ts else 0\n",
    "    repeat += sum([1 for idx, __ in enumerate(ts) if __ in ts[:idx]])\n",
    "    not_exist += sum([1 for __ in ts if __ not in title2item])\n",
    "    in_history += sum([1 for __ in ts if __ in history])\n",
    "    target_in_history += 1 if label in history else 0\n",
    "    correct_count += 1 if len(ts) == _['input_field_data']['item_count'] else 0\n",
    "\n",
    "print(f'''top_k: {k}\n",
    "count: {count}\n",
    "recall: {recall/count:.5f}\n",
    "mrr: {mrr/count:.5f}\n",
    "ndcg: {ndcg/count:.5f}\n",
    "repeat: {repeat/count:.5f}\n",
    "not_exist: {not_exist/count:.5f}\n",
    "in_history: {in_history/count:.5f}\n",
    "target_in_history: {target_in_history/count:.5f}\n",
    "correct_count: {correct_count/count:.5f}''')\n",
    "metric.print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
